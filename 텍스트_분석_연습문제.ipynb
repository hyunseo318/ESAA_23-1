{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **| 텍스트 분석 연습 문제**\n",
        "\n",
        "- 출처 : 캐글"
      ],
      "metadata": {
        "id": "Yw5mfB-1YfRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Tokenization**\n",
        "\n",
        "In the field of Natural Language Processing, tokenization basically refers to splitting up a larger body of text into smaller lines or words.\n",
        "\n",
        "There are mainly two types of tokenization :\n",
        "\n",
        "- Sentence Tokenization\n",
        "- Word Tokenization"
      ],
      "metadata": {
        "id": "zZBGXubsY6lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import package\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize "
      ],
      "metadata": {
        "id": "zpux756aZRgB",
        "outputId": "e8aece0b-c832-4933-ca86-3a88ecbc04f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample text to perform our operations\n",
        "text = \"Hi, My name is Amartya Nambiar. I am a Computer Science Engineer. My favourite color is black\""
      ],
      "metadata": {
        "id": "-vKDqW1WZcjr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "id": "GowligokZeEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665f1958-e3e6-433b-8988-acb57b32274c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi, My name is Amartya Nambiar.',\n",
              " 'I am a Computer Science Engineer.',\n",
              " 'My favourite color is black']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 토큰화, 길이 출력\n",
        "words =word_tokenize(text)\n",
        "print(len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "id": "pY1VFCkVaDrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b16274-3977-4c05-b414-70c8a86db659"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "792\n",
            "['a', 'new', 'entry', 'in', 'the', '``', 'revisionist', 'history', '``', 'genre', 'of', 'filmmaking', ',', 'dick', 'suggests', 'that', 'two', 'not-too-bright', 'teenage', 'girls', 'are', 'the', 'cause', 'of', 'the', 'uncovering', 'of', 'the', 'nation', \"'s\", 'biggest', 'presidential', 'scandal', '.', 'kirsten', 'dunst', 'and', 'michelle', 'williams', 'star', 'betsy', 'and', 'arlene', ',', 'who', 'while', 'trying', 'to', 'deliver', 'a', 'fan', 'letter', 'from', 'arlene', \"'s\", 'watergate', 'hotel', 'room', ',', 'accidentally', 'stumble', 'across', 'g', '.', 'gordon', 'liddy', '(', 'played', 'dead-on', 'by', 'harry', 'shearer', ')', 'and', 'the', 'infamous', 'break-in', '.', 'when', 'they', 'recognize', 'liddy', 'later', 'on', 'during', 'a', 'white', 'house', 'field', 'trip', ',', 'they', 'are', 'ushered', 'into', 'a', 'conference', 'room', ',', 'questioned', 'as', 'to', 'what', 'they', 'know', ',', 'and', 'leave', 'as', 'official', 'presidential', 'dog', 'walkers', '.', 'the', 'girls', 'manage', 'to', 'unwittingly', 'uncover', 'every', 'bit', 'of', 'the', 'watergate', 'scandal', 'while', 'performing', 'their', 'duties', ',', 'but', 'have', 'no', 'clue', 'as', 'to', 'what', 'they', 'are', 'getting', 'involved', 'with', '.', 'when', 'they', 'discover', 'that', 'nixon', '(', 'another', 'dead-on', 'performance', 'by', 'dan', 'hedaya', ',', 'who', 'actually', 'favors', 'nixon', 'slightly', ',', 'unlike', 'anthony', 'hopkins', ')', 'has', 'been', 'abusive', 'to', 'checkers', ',', 'the', 'presidential', 'dog', ',', 'thanks', 'to', 'the', 'conversations', 'that', 'he', 'always', 'recorded', ',', 'they', 'quit', 'and', 'become', 'disillusioned', '.', 'during', 'a', 'prank', 'phone', 'call', 'the', 'girls', 'make', 'to', 'woodward', 'and', 'bernstein', ',', 'events', 'are', 'set', 'into', 'motion', 'that', 'eventually', 'lead', 'to', 'the', 'president', \"'s\", 'resignation', '.', 'this', 'film', 'starts', 'off', 'promisingly', 'with', 'an', 'aged', 'woodward', 'and', 'bernstein', 'arguing', 'with', 'each', 'other', 'on', 'an', 'obvious', 'larry', 'king-type', 'talk', 'show', '(', 'featuring', 'a', 'cameo', 'by', 'french', 'stewart', ')', 'about', 'revealing', 'the', 'identity', 'of', '``', 'deep', 'throat', '``', '.', 'from', 'there', ',', 'we', 'are', 'subjected', 'to', 'bodily', 'function', 'humor', 'and', 'just', 'about', 'every', 'bad', '``', 'dick', '``', 'joke', 'one', 'can', 'derive', 'from', 'this', 'type', 'of', 'supposed', 'comedy', '.', 'at', 'one', 'point', ',', 'the', 'girls', 'are', 'having', 'to', 'scream', 'over', 'a', 'high', 'school', 'band', 'playing', 'on', 'the', 'steps', 'of', 'the', 'lincoln', 'memorial', '.', 'the', 'band', 'manages', 'to', 'stop', 'right', 'as', 'dunst', 'screams', '``', 'you', 'have', 'to', 'stop', 'letting', 'dick', 'run', 'your', 'life', '!', '``', 'much', 'to', 'the', 'horror', 'of', 'everyone', 'standing', 'within', 'earshot', '.', 'several', 'other', 'variations', 'on', 'this', 'wordplay', 'surface', 'all', 'throughout', 'the', 'film', '.', 'if', 'this', 'movie', 'had', 'been', 'smarter', 'i', 'would', 'have', 'been', 'less', 'likely', 'to', 'fault', 'it', \"'s\", 'juvenile', 'bathroom', 'humor', ',', 'but', 'it', \"'s\", 'not', '.', 'the', 'film', 'was', 'apparently', 'made', 'for', 'relatively', 'younger', 'people', 'because', 'every', 'major', 'player', 'in', 'the', 'watergate', 'scandal', 'is', 'introduced', 'and', 'shoved', 'down', 'the', 'audience', \"'s\", 'throat', 'in', 'the', 'least', 'subtle', 'way', 'possible', '.', 'i', 'do', \"n't\", 'recall', 'oliver', 'stone', \"'s\", 'nixon', 'having', 'to', 'pander', 'to', 'it', \"'s\", 'audience', ',', 'but', 'of', 'course', 'that', 'film', 'was', \"n't\", 'a', 'comedy', 'aimed', 'squarely', 'at', 'a', '13-20', 'year-old', 'film', 'going', 'audience', '.', 'the', 'only', 'redeeming', 'thing', 'about', 'this', 'movie', 'is', 'it', \"'s\", 'remarkable', 'supporting', 'cast', '.', 'i', 'wanted', 'to', 'see', 'more', 'of', 'ferrell', 'and', 'mcculloch', \"'s\", 'woodward', 'and', 'bernstein', '.', 'those', 'two', 'characters', 'are', 'the', 'sole', 'basis', 'for', 'my', 'rating', '.', 'i', 'wish', 'they', 'had', 'been', 'given', 'more', 'screen', 'time', ',', 'but', 'unfortunately', ',', 'they', 'are', 'only', 'relegated', 'to', 'the', 'final', 'half-hour', '.', 'their', 'constant', 'bickering', 'and', 'fighting', 'over', 'trying', 'to', 'get', 'the', 'story', 'are', 'a', 'major', 'highlight', ',', 'especially', 'mcculloch', \"'s\", 'constant', 'thwarting', 'of', 'ferrell', \"'s\", 'attempts', 'to', 'gather', 'information', 'from', 'the', 'girls', '(', 'who', ',', 'in', 'the', 'course', 'of', 'the', 'narrative', 'are', 'revealed', 'as', 'deep', 'throat', ',', 'so', 'named', 'thanks', 'to', 'an', 'ill', 'planned', 'trip', 'to', 'a', 'porno', 'theater', 'by', 'betsy', \"'s\", 'brother', ')', '.', 'the', 'other', 'members', 'of', 'the', 'cast', 'are', 'excellent', 'in', 'their', 'portrayals', 'of', 'their', 'particular', 'characters', ',', 'but', 'are', 'given', 'nothing', 'to', 'work', 'with', '.', 'i', \"'d\", 'like', 'to', 'see', 'the', 'same', 'cast', 'portray', 'these', 'characters', 'in', 'a', 'script', 'more', 'suited', 'towards', 'their', 'comedic', 'abilities', '.', 'as', 'for', 'the', 'two', 'leads', ',', 'dunst', 'and', 'williams', 'can', 'definitely', 'do', 'better', '.', 'they', 'come', 'off', 'as', 'what', 'could', 'best', 'be', 'described', 'as', 'romy', 'and', 'michele', ':', 'the', 'early', 'years', 'in', 'this', 'particular', 'film', ',', 'a', 'highly', 'dubious', 'distinction', 'at', 'best', '.', 'stay', 'through', 'the', 'first', 'half', 'of', 'the', 'end', 'credits', 'though', ',', 'to', 'see', 'an', 'interesting', 'scene', 'involving', 'dunst', 'and', 'williams', 'suggestively', 'sucking', 'on', 'lollipops', 'emblazoned', 'with', 'the', 'title', 'of', 'the', 'movie', '.', 'an', 'excellent', 'idea', 'marred', 'by', 'poor', 'execution', ',', 'dick', 'could', 'have', 'been', 'a', 'great', 'movie', '.', 'less', 'of', 'the', 'juvenile', 'humor', 'and', 'more', 'of', 'the', 'smarter', 'comedy', 'displayed', 'by', 'the', 'woodward', 'and', 'bernstein', 'scenes', ',', 'could', 'have', 'made', 'this', 'film', 'a', 'wonderful', 'satire', 'of', 'the', 'nixon', 'presidency', 'as', 'seen', 'through', 'the', 'eyes', 'of', 'two', 'naive', 'fifteen', 'year', 'olds', '.', 'as', 'it', 'stands', 'though', ',', 'dick', 'offers', 'nothing', 'but', 'what', 'filmmaker', 'kevin', 'smith', 'so', 'accurately', 'defines', 'as', '``', 'dick', 'and', 'poopie', '``', 'jokes', '.', 'and', 'that', ',', 'to', 'me', ',', 'does', 'not', 'make', 'a', 'funny', 'movie', '.', '[', 'pg-13', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Stopwords & Flushing them**\n",
        "\n",
        "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence."
      ],
      "metadata": {
        "id": "unjlrUQTaiGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords') \n",
        "from nltk.corpus import stopwords  "
      ],
      "metadata": {
        "id": "Rf5p8-7KazcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67803841-43a9-4458-b853-3f68b33b1ddb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english stopword 불러오기, 15개만 확인\n",
        "stop = stopwords.words('english')\n",
        "print(len(stop))\n",
        "print(stop[:15])"
      ],
      "metadata": {
        "id": "f8kqXiktbBSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d34516-cdfb-489a-ca55-25212ac06227"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필터링을 통해 text에서 stopword 제거\n",
        "clean = [i for i in words if not i in stop]     \n",
        "print(len(clean))\n",
        "print(clean)"
      ],
      "metadata": {
        "id": "CTeQujmRbPZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6eb4df9-387d-401f-8fed-f9f1b20ed5e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "485\n",
            "['new', 'entry', '``', 'revisionist', 'history', '``', 'genre', 'filmmaking', ',', 'dick', 'suggests', 'two', 'not-too-bright', 'teenage', 'girls', 'cause', 'uncovering', 'nation', \"'s\", 'biggest', 'presidential', 'scandal', '.', 'kirsten', 'dunst', 'michelle', 'williams', 'star', 'betsy', 'arlene', ',', 'trying', 'deliver', 'fan', 'letter', 'arlene', \"'s\", 'watergate', 'hotel', 'room', ',', 'accidentally', 'stumble', 'across', 'g', '.', 'gordon', 'liddy', '(', 'played', 'dead-on', 'harry', 'shearer', ')', 'infamous', 'break-in', '.', 'recognize', 'liddy', 'later', 'white', 'house', 'field', 'trip', ',', 'ushered', 'conference', 'room', ',', 'questioned', 'know', ',', 'leave', 'official', 'presidential', 'dog', 'walkers', '.', 'girls', 'manage', 'unwittingly', 'uncover', 'every', 'bit', 'watergate', 'scandal', 'performing', 'duties', ',', 'clue', 'getting', 'involved', '.', 'discover', 'nixon', '(', 'another', 'dead-on', 'performance', 'dan', 'hedaya', ',', 'actually', 'favors', 'nixon', 'slightly', ',', 'unlike', 'anthony', 'hopkins', ')', 'abusive', 'checkers', ',', 'presidential', 'dog', ',', 'thanks', 'conversations', 'always', 'recorded', ',', 'quit', 'become', 'disillusioned', '.', 'prank', 'phone', 'call', 'girls', 'make', 'woodward', 'bernstein', ',', 'events', 'set', 'motion', 'eventually', 'lead', 'president', \"'s\", 'resignation', '.', 'film', 'starts', 'promisingly', 'aged', 'woodward', 'bernstein', 'arguing', 'obvious', 'larry', 'king-type', 'talk', 'show', '(', 'featuring', 'cameo', 'french', 'stewart', ')', 'revealing', 'identity', '``', 'deep', 'throat', '``', '.', ',', 'subjected', 'bodily', 'function', 'humor', 'every', 'bad', '``', 'dick', '``', 'joke', 'one', 'derive', 'type', 'supposed', 'comedy', '.', 'one', 'point', ',', 'girls', 'scream', 'high', 'school', 'band', 'playing', 'steps', 'lincoln', 'memorial', '.', 'band', 'manages', 'stop', 'right', 'dunst', 'screams', '``', 'stop', 'letting', 'dick', 'run', 'life', '!', '``', 'much', 'horror', 'everyone', 'standing', 'within', 'earshot', '.', 'several', 'variations', 'wordplay', 'surface', 'throughout', 'film', '.', 'movie', 'smarter', 'would', 'less', 'likely', 'fault', \"'s\", 'juvenile', 'bathroom', 'humor', ',', \"'s\", '.', 'film', 'apparently', 'made', 'relatively', 'younger', 'people', 'every', 'major', 'player', 'watergate', 'scandal', 'introduced', 'shoved', 'audience', \"'s\", 'throat', 'least', 'subtle', 'way', 'possible', '.', \"n't\", 'recall', 'oliver', 'stone', \"'s\", 'nixon', 'pander', \"'s\", 'audience', ',', 'course', 'film', \"n't\", 'comedy', 'aimed', 'squarely', '13-20', 'year-old', 'film', 'going', 'audience', '.', 'redeeming', 'thing', 'movie', \"'s\", 'remarkable', 'supporting', 'cast', '.', 'wanted', 'see', 'ferrell', 'mcculloch', \"'s\", 'woodward', 'bernstein', '.', 'two', 'characters', 'sole', 'basis', 'rating', '.', 'wish', 'given', 'screen', 'time', ',', 'unfortunately', ',', 'relegated', 'final', 'half-hour', '.', 'constant', 'bickering', 'fighting', 'trying', 'get', 'story', 'major', 'highlight', ',', 'especially', 'mcculloch', \"'s\", 'constant', 'thwarting', 'ferrell', \"'s\", 'attempts', 'gather', 'information', 'girls', '(', ',', 'course', 'narrative', 'revealed', 'deep', 'throat', ',', 'named', 'thanks', 'ill', 'planned', 'trip', 'porno', 'theater', 'betsy', \"'s\", 'brother', ')', '.', 'members', 'cast', 'excellent', 'portrayals', 'particular', 'characters', ',', 'given', 'nothing', 'work', '.', \"'d\", 'like', 'see', 'cast', 'portray', 'characters', 'script', 'suited', 'towards', 'comedic', 'abilities', '.', 'two', 'leads', ',', 'dunst', 'williams', 'definitely', 'better', '.', 'come', 'could', 'best', 'described', 'romy', 'michele', ':', 'early', 'years', 'particular', 'film', ',', 'highly', 'dubious', 'distinction', 'best', '.', 'stay', 'first', 'half', 'end', 'credits', 'though', ',', 'see', 'interesting', 'scene', 'involving', 'dunst', 'williams', 'suggestively', 'sucking', 'lollipops', 'emblazoned', 'title', 'movie', '.', 'excellent', 'idea', 'marred', 'poor', 'execution', ',', 'dick', 'could', 'great', 'movie', '.', 'less', 'juvenile', 'humor', 'smarter', 'comedy', 'displayed', 'woodward', 'bernstein', 'scenes', ',', 'could', 'made', 'film', 'wonderful', 'satire', 'nixon', 'presidency', 'seen', 'eyes', 'two', 'naive', 'fifteen', 'year', 'olds', '.', 'stands', 'though', ',', 'dick', 'offers', 'nothing', 'filmmaker', 'kevin', 'smith', 'accurately', 'defines', '``', 'dick', 'poopie', '``', 'jokes', '.', ',', ',', 'make', 'funny', 'movie', '.', '[', 'pg-13', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# punctuation('.', ',') 제거\n",
        "import string \n",
        "punctuations = list(string.punctuation)        \n",
        "stop += punctuations                           \n",
        "words =word_tokenize(text.lower())\n",
        "clean_lower = [i for i in words if not i in stop]\n",
        "print(len(clean_lower))\n",
        "print(clean_lower)"
      ],
      "metadata": {
        "id": "lxAH2ytMb3TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98267e0f-fb92-4e9b-9e71-cf8cdb239402"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "413\n",
            "['new', 'entry', '``', 'revisionist', 'history', '``', 'genre', 'filmmaking', 'dick', 'suggests', 'two', 'not-too-bright', 'teenage', 'girls', 'cause', 'uncovering', 'nation', \"'s\", 'biggest', 'presidential', 'scandal', 'kirsten', 'dunst', 'michelle', 'williams', 'star', 'betsy', 'arlene', 'trying', 'deliver', 'fan', 'letter', 'arlene', \"'s\", 'watergate', 'hotel', 'room', 'accidentally', 'stumble', 'across', 'g', 'gordon', 'liddy', 'played', 'dead-on', 'harry', 'shearer', 'infamous', 'break-in', 'recognize', 'liddy', 'later', 'white', 'house', 'field', 'trip', 'ushered', 'conference', 'room', 'questioned', 'know', 'leave', 'official', 'presidential', 'dog', 'walkers', 'girls', 'manage', 'unwittingly', 'uncover', 'every', 'bit', 'watergate', 'scandal', 'performing', 'duties', 'clue', 'getting', 'involved', 'discover', 'nixon', 'another', 'dead-on', 'performance', 'dan', 'hedaya', 'actually', 'favors', 'nixon', 'slightly', 'unlike', 'anthony', 'hopkins', 'abusive', 'checkers', 'presidential', 'dog', 'thanks', 'conversations', 'always', 'recorded', 'quit', 'become', 'disillusioned', 'prank', 'phone', 'call', 'girls', 'make', 'woodward', 'bernstein', 'events', 'set', 'motion', 'eventually', 'lead', 'president', \"'s\", 'resignation', 'film', 'starts', 'promisingly', 'aged', 'woodward', 'bernstein', 'arguing', 'obvious', 'larry', 'king-type', 'talk', 'show', 'featuring', 'cameo', 'french', 'stewart', 'revealing', 'identity', '``', 'deep', 'throat', '``', 'subjected', 'bodily', 'function', 'humor', 'every', 'bad', '``', 'dick', '``', 'joke', 'one', 'derive', 'type', 'supposed', 'comedy', 'one', 'point', 'girls', 'scream', 'high', 'school', 'band', 'playing', 'steps', 'lincoln', 'memorial', 'band', 'manages', 'stop', 'right', 'dunst', 'screams', '``', 'stop', 'letting', 'dick', 'run', 'life', '``', 'much', 'horror', 'everyone', 'standing', 'within', 'earshot', 'several', 'variations', 'wordplay', 'surface', 'throughout', 'film', 'movie', 'smarter', 'would', 'less', 'likely', 'fault', \"'s\", 'juvenile', 'bathroom', 'humor', \"'s\", 'film', 'apparently', 'made', 'relatively', 'younger', 'people', 'every', 'major', 'player', 'watergate', 'scandal', 'introduced', 'shoved', 'audience', \"'s\", 'throat', 'least', 'subtle', 'way', 'possible', \"n't\", 'recall', 'oliver', 'stone', \"'s\", 'nixon', 'pander', \"'s\", 'audience', 'course', 'film', \"n't\", 'comedy', 'aimed', 'squarely', '13-20', 'year-old', 'film', 'going', 'audience', 'redeeming', 'thing', 'movie', \"'s\", 'remarkable', 'supporting', 'cast', 'wanted', 'see', 'ferrell', 'mcculloch', \"'s\", 'woodward', 'bernstein', 'two', 'characters', 'sole', 'basis', 'rating', 'wish', 'given', 'screen', 'time', 'unfortunately', 'relegated', 'final', 'half-hour', 'constant', 'bickering', 'fighting', 'trying', 'get', 'story', 'major', 'highlight', 'especially', 'mcculloch', \"'s\", 'constant', 'thwarting', 'ferrell', \"'s\", 'attempts', 'gather', 'information', 'girls', 'course', 'narrative', 'revealed', 'deep', 'throat', 'named', 'thanks', 'ill', 'planned', 'trip', 'porno', 'theater', 'betsy', \"'s\", 'brother', 'members', 'cast', 'excellent', 'portrayals', 'particular', 'characters', 'given', 'nothing', 'work', \"'d\", 'like', 'see', 'cast', 'portray', 'characters', 'script', 'suited', 'towards', 'comedic', 'abilities', 'two', 'leads', 'dunst', 'williams', 'definitely', 'better', 'come', 'could', 'best', 'described', 'romy', 'michele', 'early', 'years', 'particular', 'film', 'highly', 'dubious', 'distinction', 'best', 'stay', 'first', 'half', 'end', 'credits', 'though', 'see', 'interesting', 'scene', 'involving', 'dunst', 'williams', 'suggestively', 'sucking', 'lollipops', 'emblazoned', 'title', 'movie', 'excellent', 'idea', 'marred', 'poor', 'execution', 'dick', 'could', 'great', 'movie', 'less', 'juvenile', 'humor', 'smarter', 'comedy', 'displayed', 'woodward', 'bernstein', 'scenes', 'could', 'made', 'film', 'wonderful', 'satire', 'nixon', 'presidency', 'seen', 'eyes', 'two', 'naive', 'fifteen', 'year', 'olds', 'stands', 'though', 'dick', 'offers', 'nothing', 'filmmaker', 'kevin', 'smith', 'accurately', 'defines', '``', 'dick', 'poopie', '``', 'jokes', 'make', 'funny', 'movie', 'pg-13']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Stemming**\n",
        "\n",
        "Stemming is a technique used to extract the base form of the words by removing affixes from them. It is just like cutting down the branches of a tree to its stems. For example, the stem of the words eating, eats, eaten is eat.\n",
        "\n",
        "There are mainly two widely used Stemmer Algorithms:\n",
        "\n",
        "- Porter Stemmer (we'll work on this)\n",
        "- Lancaster Stem"
      ],
      "metadata": {
        "id": "yEAlzfMhcBcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "EQQuNe0McNBg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ps 객체 생성 후 stemming , example 최소 3개 임의 생성 후 시도해보기\n",
        "# example1= ['helps', 'helping', 'helped']\n",
        "\n",
        "ps = PorterStemmer()         \n",
        "example = ['helps','helping','helped']   \n",
        "stemmed_example = [ps.stem(i) for i in example]\n",
        "stemmed_example"
      ],
      "metadata": {
        "id": "hp_atqYwdkR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0cc797-fda1-459c-e0b5-02d5993714da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['help', 'help', 'help']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps.stem('happiness') # but it isn't always the best choice"
      ],
      "metadata": {
        "id": "mwMDJ3ZaduyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a59e1299-1c05-4e50-f496-56388e4b3946"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Parts of Speech**\n",
        "\n",
        "To know what is the context of a particular word\n",
        "\n",
        "For example : Shyam is a Proper Noun, Desk is a Noun and Happy is an adjective."
      ],
      "metadata": {
        "id": "71eO1YE1dwBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "text = movie_reviews.raw(\"neg/cv954_19932.txt\") "
      ],
      "metadata": {
        "id": "S2iVOPi4eEKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d92eaf-d9c4-4bc2-b012-c93616ded85d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply pos_tag(), print result"
      ],
      "metadata": {
        "id": "vcWgmScAedLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos_tag(word_tokenize(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pUSmNwzLjWw",
        "outputId": "efcf82bc-f9bc-4a46-9dba-6339d8a7f1c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hi', 'NNP'), (',', ','), ('My', 'NNP'), ('name', 'NN'), ('is', 'VBZ'), ('Amartya', 'NNP'), ('Nambiar', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Engineer', 'NNP'), ('.', '.'), ('My', 'NNP'), ('favourite', 'JJ'), ('color', 'NN'), ('is', 'VBZ'), ('black', 'JJ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Lemmatization**\n",
        "\n",
        "PorterStemmer class chops off the suffixes from the word but this isn't the best thing to apply to clean our data.\n",
        "\n",
        "Stemming technique only looks at the form of the word whereas Lemmatization technique looks at the meaning of the word. It means after applying lemmatization, we will always get a valid word."
      ],
      "metadata": {
        "id": "NrFml-IJepQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import package\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "xWF0Ibznetk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601abff9-d19e-4917-c7aa-6810e5c89c74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatize 'believes', 'happiness'\n",
        "lem = WordNetLemmatizer()\n",
        "lem.lemmatize('believes')"
      ],
      "metadata": {
        "id": "C-abWCqffiwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6affd242-a2bb-4832-b33f-71e441ce5d27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'belief'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem = WordNetLemmatizer()\n",
        "lem.lemmatize('happiness')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZZ4EcucoQQzd",
        "outputId": "6c7ce04f-010b-4856-a4ea-4a0bfa75dd41"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happiness'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem.lemmatize('believes', pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "De0E848uQqDc",
        "outputId": "cc27262f-218d-49e9-b9ac-c696d7e5f6a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'believes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem.lemmatize('happiness', pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HLGGJJ-8QtQR",
        "outputId": "6b17d36b-efb4-4d62-90df-838ca580bd79"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happiness'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem.lemmatize('believes', pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KBe6QPU1QvpI",
        "outputId": "7456c729-f7d6-4f67-d619-800e6c36b5e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'believe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem.lemmatize('happiness', pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HGVEd6onQzL7",
        "outputId": "2a7b436a-5da5-4ec9-a98e-6218e08ef9b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happiness'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}